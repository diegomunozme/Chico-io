# config.py

CHROMA_COLLECTION_NAME = "data"
CHROMA_PATH = "chroma"  # Ensure this path matches your existing chroma directory
OLLAMA_SERVER_URL = "http://3.144.114.244:11434"  # Your Ollama server URL
OLLAMA_EMBED_MODEL = "mxbai-embed-large"  # Your embedding model
OLLAMA_LLM_MODEL = "llama3.2:latest"  # Replace with your actual Ollama LLM model name
DATA_PATH='data'